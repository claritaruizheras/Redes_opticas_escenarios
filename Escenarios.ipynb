{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escenarios integrados en un mismo script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creación del kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar al máximo la instalación del simulador, se ha simplificado la creación del kernel en esta celda de jupyternotebook. Esta <font color=\"red\">**solo se debe ejecutar la primera vez que se abre el simulador**</font>, ya que simplemente busca facilitar la instalación de dependencias inicial. El tiempo de ejecución de esta celda puede ser largo. Esto se debe a que en ella no solo se crea el kernel sino que se instalan todas las librerias necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def run_command(command):\n",
    "    \"\"\"Ejecuta comando y retorna True si fue exitoso\"\"\"\n",
    "    print(f\"Ejecutando: {command}\")\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=300)\n",
    "        if result.stdout:\n",
    "            print(result.stdout.strip())\n",
    "        if result.returncode != 0 and result.stderr:\n",
    "            print(f\"Error: {result.stderr.strip()}\")\n",
    "        return result.returncode == 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False\n",
    "        \n",
    "ENV_NAME = \"redes_opticas\"\n",
    "\n",
    "# Eliminar entorno anterior\n",
    "print(\"Eliminando entorno anterior...\")\n",
    "run_command(f\"conda env remove -n {ENV_NAME} -y\")\n",
    "\n",
    "# Crear nuevo entorno con Python 3.12\n",
    "print(\"Creando entorno con Python 3.12...\")\n",
    "if run_command(f\"conda create -n {ENV_NAME} python=3.12 -y\"):\n",
    "    \n",
    "    # Instalar jupyter e ipykernel\n",
    "    print(\"Instalando jupyter...\")\n",
    "    if run_command(f\"conda run -n {ENV_NAME} pip install jupyter ipykernel\"):\n",
    "        \n",
    "        # Instalar desde requirements.txt\n",
    "        print(\"Instalando desde requirements.txt...\")\n",
    "        if run_command(f\"conda run -n {ENV_NAME} pip install -r requirements.txt\"):\n",
    "            print(\"Requirements.txt instalado correctamente\")\n",
    "        else:\n",
    "            print(\"Error con requirements.txt, instalando paquetes básicos...\")\n",
    "            run_command(f\"conda run -n {ENV_NAME} pip install gymnasium numpy matplotlib pandas stable-baselines3 scipy\")\n",
    "        \n",
    "        # Configurar kernel\n",
    "        print(\"Configurando kernel...\")\n",
    "        if run_command(f'conda run -n {ENV_NAME} python -m ipykernel install --user --name={ENV_NAME} --display-name=\"Redes Opticas\"'):\n",
    "            print(\"CONFIGURACION COMPLETADA\")\n",
    "        else:\n",
    "            print(\"Error configurando kernel\")\n",
    "    else:\n",
    "        print(\"Error instalando jupyter\")\n",
    "else:\n",
    "    print(\"Error creando entorno con Python\")\n",
    "    print(\"Verifica que tengas conda actualizado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasos siguientes:\n",
    "1. Reinicia el kernel\n",
    "2. Cambia al kernel `'Redes Opticas'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Librerias necesarias para el simulador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\envs\\redes_opticas\\Lib\\site-packages\\gymnasium\\envs\\registration.py:636: UserWarning: \u001b[33mWARN: Overriding environment RedesOpticasEnv-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from rich.prompt import Prompt\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from custom_env.redes_opticas_env import RedesOpticasEnv as RedesOpticasEnv1\n",
    "from custom_env.redes_opticas_env_2 import RedesOpticasEnv as RedesOpticasEnv2\n",
    "from custom_env.redes_opticas_env_3 import RedesOpticasEnv as RedesOpticasEnv3\n",
    "from custom_env.redes_opticas_env_4 import RedesOpticasEnv as RedesOpticasEnv4\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Declaración de los distintos entornos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecciona el entorno a inicializar:\n",
      "1: RedesOpticasEnv1\n",
      "2: RedesOpticasEnv2\n",
      "3: RedesOpticasEnv3\n",
      "4: RedesOpticasEnv4\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Introduce el número de entorno (1, 2, 3 o 4):  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_env(num_ont, TxRate=10e9,B_guaranteed=[], n_ciclos=200, rank=0, seed=0):\n",
    "    def _init():\n",
    "        env = RedesOpticasEnv1(render_mode=None,seed=seed, num_ont=num_ont, TxRate=TxRate, B_guaranteed=B_guaranteed,n_ciclos=n_ciclos)\n",
    "        env = Monitor(env, filename=\"./reward_logs/reward\")\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "def make_env_2(num_ont, TxRate=10e9,B_guaranteed=[], n_ciclos=200, rank=0, seed=0):\n",
    "    def _init():\n",
    "        env = RedesOpticasEnv2(render_mode=None,seed=seed, num_ont=num_ont, TxRate=TxRate, B_guaranteed=B_guaranteed,n_ciclos=n_ciclos)\n",
    "        env = Monitor(env, filename=\"./reward_logs/reward\")\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "def make_env_3(num_ont, TxRate=10e9,B_guaranteed=[], n_ciclos=200, rank=0, seed=0):\n",
    "    def _init():\n",
    "        env = RedesOpticasEnv3(render_mode=None,seed=seed, num_ont=num_ont, TxRate=TxRate, B_guaranteed=B_guaranteed,n_ciclos=n_ciclos)\n",
    "        env = Monitor(env, filename=\"./reward_logs/reward\")\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "def make_env_4(num_ont, TxRate=10e9,B_guaranteed=[], n_ciclos=200, rank=0, seed=0):\n",
    "    def _init():\n",
    "        env = RedesOpticasEnv4(render_mode=None,seed=seed, num_ont=num_ont, TxRate=TxRate, B_guaranteed=B_guaranteed,n_ciclos=n_ciclos)\n",
    "        env = Monitor(env, filename=\"./reward_logs/reward\")\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"Selecciona el entorno a inicializar:\")\n",
    "    print(\"1: RedesOpticasEnv1\")\n",
    "    print(\"2: RedesOpticasEnv2\")\n",
    "    print(\"3: RedesOpticasEnv3\")\n",
    "    print(\"4: RedesOpticasEnv4\")\n",
    "    entorno_seleccionado = input(\"Introduce el número de entorno (1, 2, 3 o 4): \")\n",
    "\n",
    "    if entorno_seleccionado == \"1\":\n",
    "        make_env_func = make_env\n",
    "    elif entorno_seleccionado == \"2\":\n",
    "        make_env_func = make_env_2\n",
    "    elif entorno_seleccionado == \"3\":\n",
    "        make_env_func = make_env_3\n",
    "    elif entorno_seleccionado == \"4\":\n",
    "        make_env_func = make_env_4\n",
    "    else:\n",
    "        raise ValueError(\"Selección de entorno no válida. Debe ser 1, 2, 3 o 4.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definición del modelo e hiperparámetro del agente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    if entorno_seleccionado == \"1\" or entorno_seleccionado == \"2\" or entorno_seleccionado == \"3\":\n",
    "            env_id = 'RedesOpticasEnv-v0'  \n",
    "            seed = np.random.randint(0, 10)  \n",
    "            num_ont=16\n",
    "            TxRate=10e9\n",
    "            T=0.002\n",
    "            B_available=TxRate*T\n",
    "            B_max=[0]*num_ont\n",
    "            B_guaranteed=[600e6]*num_ont\n",
    "            for i in range(num_ont):\n",
    "                B_max[i]=B_guaranteed[i]*T\n",
    "            n_ciclos= 400\n",
    "            vec_env = DummyVecEnv([make_env_func(num_ont,TxRate,B_guaranteed,n_ciclos, rank=0, seed=42)])\n",
    "\n",
    "            model = PPO(\n",
    "                \"MlpPolicy\",\n",
    "                vec_env,\n",
    "                n_steps=256,  \n",
    "                batch_size=128,  \n",
    "                learning_rate =3.593813663804625e-05,\n",
    "                n_epochs= 20,\n",
    "                gamma= 0.9286872177396786,\n",
    "                gae_lambda= 0.9797433034291914,\n",
    "                clip_range= 0.2847644623515798,\n",
    "                clip_range_vf= 0.1988417058668721,\n",
    "                max_grad_norm= 3.1942678576486786,\n",
    "                device=\"cpu\"\n",
    "            )\n",
    "\n",
    "\n",
    "    elif entorno_seleccionado == \"4\":\n",
    "            env_id = 'RedesOpticasEnv-v0'  \n",
    "            seed = np.random.randint(0, 10)\n",
    "            num_ont = 16\n",
    "            num_guaranteed_ont = 6\n",
    "            TxRate = 10e9\n",
    "            T = 0.002\n",
    "            B_guaranteed = [600e6 if i < num_guaranteed_ont else 0 for i in range(num_ont)]\n",
    "            B_max = [b * T for b in B_guaranteed]\n",
    "            n_ciclos = 4000\n",
    "            vec_env = DummyVecEnv([make_env_func(num_ont,TxRate,B_guaranteed,n_ciclos, rank=0, seed=42)])\n",
    "\n",
    "            model = PPO(\n",
    "                \"MlpPolicy\", \n",
    "                vec_env, \n",
    "                learning_rate= 0.001,\n",
    "                n_steps= 256,\n",
    "                batch_size= 32,\n",
    "                n_epochs= 30,\n",
    "                gamma= 0.94,\n",
    "                gae_lambda= 0.8878686405859539,\n",
    "                clip_range= 0.3492601502681344,\n",
    "                clip_range_vf= 0.14642359654938747,\n",
    "                max_grad_norm= 3.460846959513738,\n",
    "                device=\"cpu\"\n",
    "            )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">   4%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">4,352/100,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:02:31</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:54:17</span> , <span style=\"color: #800000; text-decoration-color: #800000\">29 it/s</span> ]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m   4%\u001b[0m \u001b[38;2;249;38;114m━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4,352/100,000 \u001b[0m [ \u001b[33m0:02:31\u001b[0m < \u001b[36m0:54:17\u001b[0m , \u001b[31m29 it/s\u001b[0m ]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # Registro del tiempo antes del entrenamiento\n",
    "    start_time = time.time()\n",
    "    # Línea de entrenamiento del modelo\n",
    "    model.learn(total_timesteps=100000, progress_bar=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    # Cálculo del tiempo total de entrenamiento\n",
    "    training_time = end_time - start_time\n",
    "    print(f\"El tiempo de entrenamiento fue de {training_time} segundos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fase de test del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    from tqdm import trange\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    #Establecemos un unico episodio a investigar\n",
    "    num_test_episodes = 1 \n",
    "\n",
    "    # Lista para guardar la información de cada episodio\n",
    "    episode_info = []  \n",
    "\n",
    "    # Lista de en cada ont guardar el valor de su capacidad, de entrada salida y del pendiente(entrada-salida)\n",
    "    trafico_entrada_onts= []\n",
    "    B_alloc_onts = []\n",
    "    trafico_colas_onts=[]\n",
    "\n",
    "    #Capacidad de la OLT\n",
    "    tamano_cola=[]\n",
    "    # Lista para guardar los valores de JFI en cada paso\n",
    "    jfi_values = []  \n",
    "\n",
    "    \n",
    "    obs = vec_env.reset()  # Resetea el entorno al estado inicial\n",
    "    _states = None  # Inicializa el estado del modelo\n",
    "    \n",
    "    for episode in trange(num_test_episodes, desc=\"Test Episodios\"):\n",
    "        \n",
    "        done = False  # Inicializa 'done' para todos los entornos\n",
    "        step_counter = 0  # Contador de steps para limitar al numero de ciclos\n",
    "        while step_counter < n_ciclos:\n",
    "\n",
    "            action, _states = model.predict(obs, state=_states, deterministic=True)  # Usamos el modelo para predecir la acción\n",
    "            obs, rewards, dones, info = vec_env.step(action)\n",
    "\n",
    "            # Guardamos la información del episodio.\n",
    "            episode_info.append(info)\n",
    "            for subinfo in  info:  # Itera sobre cada sub-entorno  \n",
    "                suma = 0\n",
    "                trafico_entrada_onts.append(subinfo['trafico_entrada'])\n",
    "                B_alloc_onts.append(subinfo['B_alloc'])\n",
    "                trafico_colas_onts.append(subinfo['B_demand'])\n",
    "                if entorno_seleccionado == \"4\":\n",
    "                    jfi_values.append(subinfo['jfi_flex'])\n",
    "                \n",
    "            done |= dones  # Actualiza 'done' para todos los entornos\n",
    "            step_counter += 1  # Incrementa el contador de steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Gráficas que describen la asignación del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    def transpuesta(list_ont):\n",
    "        #Hay que hacer la matriz transpuesta de la lista\n",
    "\n",
    "        np_array = np.array(list_ont)\n",
    "        # Transponer el array\n",
    "        transposed_np_array = np_array.T\n",
    "\n",
    "        # Convertir el array transpuesto de NumPy de nuevo a una lista de listas de Python\n",
    "        list_transpuesta = transposed_np_array.tolist()\n",
    "\n",
    "        return list_transpuesta\n",
    "        \n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "    #Hallamos el valor de la lista transpuesta, para los valores de entrada y de salida\n",
    "    trafico_entrada_onts_transpuesta=transpuesta(trafico_entrada_onts)\n",
    "    B_alloc_onts_transpuesta=transpuesta(B_alloc_onts)\n",
    "    trafico_colas_onts_transpuesta=transpuesta(trafico_colas_onts)\n",
    "    \n",
    "    # Convertir list_transpuesta a un array NumPy \n",
    "    array_trafico_entrada_onts= np.array(trafico_entrada_onts_transpuesta)/2000 \n",
    "    array_B_alloc_onts= np.array(B_alloc_onts_transpuesta)/2000\n",
    "    array_pendiente= np.array(trafico_colas_onts_transpuesta)/2000\n",
    "\n",
    "    # Convertir array_transpuesta de vuelta a una lista de listas si es necesario\n",
    "    list_valores_entrada = array_trafico_entrada_onts.tolist()\n",
    "    list_valores_salida = array_B_alloc_onts.tolist()\n",
    "    list_pendiente_fin = array_pendiente.tolist()\n",
    "\n",
    "    maximo_pendiente=[]\n",
    "\n",
    "    #Hallamos el valor maximo de cada ciclo en cada ont para las graficas\n",
    "    for i in range(num_ont):\n",
    "        maximo_pendiente.append(max(list_pendiente_fin[i]))\n",
    "\n",
    "    #Hallar valores de los instantes para el grafico de barras\n",
    "\n",
    "    #Grafica del trafico de entrada y salida de cada O\n",
    "    for i in range(num_ont):\n",
    "\n",
    "        nuevo_x = np.arange(2, 2 * n_ciclos + 1, 2)  # x se duplica para cada punto\n",
    "\n",
    "        #Grafica del trafico de pareto de las redes\n",
    "        plt.figure(figsize=(12, 6))\n",
    "      \n",
    "        plt.xlabel('Tiempo en milisegundos')\n",
    "        plt.ylabel('Ancho de banda en Mbps')\n",
    "        plt.plot(nuevo_x, list_valores_entrada[i], label=f'Tráfico de entrada de la ONT {i+1}')\n",
    "        plt.plot(nuevo_x, list_valores_salida[i], label=f'Tráfico de salida de la ONT {i+1}')\n",
    "        plt.title(f'Grafica del trafico de entrada y salida de la ONT {i+1} en Mbps')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        #Grafica del trafico pendiente de la ont determinada\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.xlabel('Tiempo en milisegundos')\n",
    "        plt.ylabel('Tamaño de la cola en Mbits')\n",
    "        plt.plot(nuevo_x,list_pendiente_fin[i], label=f'Grafica del trafico pendiente de la ONT {i+1}')\n",
    "        plt.title(f'Grafica del trafico pendiente de la ONT {i+1} en Mbits en el ciclo determinado')\n",
    "        plt.show()\n",
    "\n",
    "       \n",
    "\n",
    "    df = pd.read_csv(\"./reward_logs/reward.monitor.csv\", skiprows=1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df[\"l\"].cumsum(), df[\"r\"])  # 'l' = length, 'r' = reward\n",
    "    plt.xlabel(\"Paso de tiempo\")\n",
    "    plt.ylabel(\"Recompensa acumulada\")\n",
    "    plt.title(\"Evolución de la recompensa\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    if entorno_seleccionado == \"4\":\n",
    "        \n",
    "        suma_total_B_alloc = np.sum(array_B_alloc_onts, axis=0)  \n",
    "\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.plot(nuevo_x, suma_total_B_alloc, color='tab:purple', label='Suma total B_alloc')\n",
    "        plt.xlabel('Tiempo en milisegundos')\n",
    "        plt.ylabel('Ancho de banda total asignado (Mbps)')\n",
    "        plt.title('Ancho de banda total asignado por ciclo (todas las ONTs)')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()   \n",
    "\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(nuevo_x, jfi_values[:len(nuevo_x)], label=\"JFI (ONTs flexibles)\", color='green')\n",
    "        plt.ylim(0, 1.05)\n",
    "        plt.xlabel(\"Tiempo en milisegundos\")\n",
    "        plt.ylabel(\"JFI Index\")\n",
    "        plt.title(\"Evolución del índice de equidad entre ONTs flexibles\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Redes Opticas",
   "language": "python",
   "name": "redes_opticas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
